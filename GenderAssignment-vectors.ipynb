{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a11d53-a2d9-4e43-812a-e08441581c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import  time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87c8a27-e9fa-48bb-9af0-cc3eca830e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>gen</th>\n",
       "      <th>sg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>à-côté</td>\n",
       "      <td>m</td>\n",
       "      <td>akOte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>à-coup</td>\n",
       "      <td>m</td>\n",
       "      <td>aku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>à-peu-près</td>\n",
       "      <td>m</td>\n",
       "      <td>apØpʁɛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>à-pic</td>\n",
       "      <td>m</td>\n",
       "      <td>apik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>à-plat</td>\n",
       "      <td>m</td>\n",
       "      <td>apla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31000</th>\n",
       "      <td>zurichois</td>\n",
       "      <td>m</td>\n",
       "      <td>zyʁikwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31001</th>\n",
       "      <td>zydeco</td>\n",
       "      <td>f</td>\n",
       "      <td>zidəko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31002</th>\n",
       "      <td>zygoma</td>\n",
       "      <td>m</td>\n",
       "      <td>zigOma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31003</th>\n",
       "      <td>zygote</td>\n",
       "      <td>m</td>\n",
       "      <td>zigɔt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31004</th>\n",
       "      <td>zyklon</td>\n",
       "      <td>m</td>\n",
       "      <td>ziklɔ̃</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lexeme gen       sg\n",
       "0          à-côté   m    akOte\n",
       "1          à-coup   m      aku\n",
       "2      à-peu-près   m   apØpʁɛ\n",
       "3           à-pic   m     apik\n",
       "4          à-plat   m     apla\n",
       "...           ...  ..      ...\n",
       "31000   zurichois   m  zyʁikwa\n",
       "31001      zydeco   f   zidəko\n",
       "31002      zygoma   m   zigOma\n",
       "31003      zygote   m    zigɔt\n",
       "31004      zyklon   m   ziklɔ̃\n",
       "\n",
       "[29412 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../../Recherche/flexique/git/distrib/nlexique.csv')\n",
    "df = df[df.gen!='b']\n",
    "df[['lexeme','gen','sg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9124c66e-49cd-400f-ada2-aad51ffc5864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary packages and define complementary functions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da76e30-4796-4618-b41f-d4ec7de74358",
   "metadata": {},
   "source": [
    "Reading frequency data for the corpus that was used for the vectors. This is useful to pick words that are frequent enough that we have quality vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a55f2d-2abe-469a-b997-0e33f4d26d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.read_csv('../../../../Recherche/corpus/frcowvec/frequencies-frcowvec.csv')\n",
    "freq = freq[freq.word.str.endswith('NOM')]\n",
    "freq.index = freq.word.str.split('_').str[0]\n",
    "freq=freq[freq.freq>=100]\n",
    "dd = defaultdict(int)\n",
    "freq = (freq.freq).to_dict(into=dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189366ba-47b4-41ac-a911-c2dd109d7d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>variants</th>\n",
       "      <th>gen</th>\n",
       "      <th>sg</th>\n",
       "      <th>pl</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>à-côté</td>\n",
       "      <td>à-côté:accoté</td>\n",
       "      <td>m</td>\n",
       "      <td>akOte</td>\n",
       "      <td>akOte</td>\n",
       "      <td>1583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>à-coup</td>\n",
       "      <td>à-coup</td>\n",
       "      <td>m</td>\n",
       "      <td>aku</td>\n",
       "      <td>aku</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>à-peu-près</td>\n",
       "      <td>à-peu-près</td>\n",
       "      <td>m</td>\n",
       "      <td>apØpʁɛ</td>\n",
       "      <td>apØpʁɛ</td>\n",
       "      <td>1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>à-pic</td>\n",
       "      <td>à-pic</td>\n",
       "      <td>m</td>\n",
       "      <td>apik</td>\n",
       "      <td>apik</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>à-plat</td>\n",
       "      <td>à-plat:aplat</td>\n",
       "      <td>m</td>\n",
       "      <td>apla</td>\n",
       "      <td>apla</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30997</th>\n",
       "      <td>zozo</td>\n",
       "      <td>zozo</td>\n",
       "      <td>m</td>\n",
       "      <td>zozo</td>\n",
       "      <td>zozo</td>\n",
       "      <td>5929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30998</th>\n",
       "      <td>zozotement</td>\n",
       "      <td>zozotement</td>\n",
       "      <td>m</td>\n",
       "      <td>zOzɔtəmɑ̃</td>\n",
       "      <td>zOzɔtəmɑ̃</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31001</th>\n",
       "      <td>zydeco</td>\n",
       "      <td>zydeco</td>\n",
       "      <td>f</td>\n",
       "      <td>zidəko</td>\n",
       "      <td>zidəko</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31003</th>\n",
       "      <td>zygote</td>\n",
       "      <td>zygote</td>\n",
       "      <td>m</td>\n",
       "      <td>zigɔt</td>\n",
       "      <td>zigɔt</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31004</th>\n",
       "      <td>zyklon</td>\n",
       "      <td>zyklon</td>\n",
       "      <td>m</td>\n",
       "      <td>ziklɔ̃</td>\n",
       "      <td>ziklɔ̃</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24204 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lexeme       variants gen         sg         pl  freq\n",
       "0          à-côté  à-côté:accoté   m      akOte      akOte  1583\n",
       "1          à-coup         à-coup   m        aku        aku   829\n",
       "2      à-peu-près     à-peu-près   m     apØpʁɛ     apØpʁɛ  1184\n",
       "3           à-pic          à-pic   m       apik       apik   241\n",
       "4          à-plat   à-plat:aplat   m       apla       apla   314\n",
       "...           ...            ...  ..        ...        ...   ...\n",
       "30997        zozo           zozo   m       zozo       zozo  5929\n",
       "30998  zozotement     zozotement   m  zOzɔtəmɑ̃  zOzɔtəmɑ̃   121\n",
       "31001      zydeco         zydeco   f     zidəko     zidəko   181\n",
       "31003      zygote         zygote   m      zigɔt      zigɔt   837\n",
       "31004      zyklon         zyklon   m     ziklɔ̃     ziklɔ̃   107\n",
       "\n",
       "[24204 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['freq'] = df.lexeme.apply(lambda k:freq[k])\n",
    "df=df[df.freq>=100]\n",
    "lemmas = df.lexeme.to_list()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b180987-3bfc-4ca4-b0da-75eaa486e1bc",
   "metadata": {},
   "source": [
    "Loading vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5d0d13-cb5d-4195-aa2d-d82c0cd73ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "vecspace = open('/Users/olivierbonami/Dropbox/Fichiers/Recherche/corpus/frcowvec/lemma-A-pos-bow.txt','r')\n",
    "for line in vecspace:\n",
    "    items = line.rstrip().split(' ')\n",
    "    lemma = items[0]\n",
    "    vector = [float(s) for s in items[1:]]\n",
    "    if lemma[-4:]=='_nom' and lemma[:-4] in lemmas:\n",
    "        vectors[lemma[:-4]] = vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f04c0c-20f1-42f7-a9d9-c82e85c7c62b",
   "metadata": {},
   "source": [
    "Creating a Series `gender` containing the genders of all nouns in random order, and then a DataFrame `dis_pred` with the corresponding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5202aca-999f-4e25-b507-2bd583bf68f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57676417121137\n"
     ]
    }
   ],
   "source": [
    "df.index=df.lexeme\n",
    "genders = df.gen.sample(frac=1)\n",
    "print(len(df.gen[df.gen=='m'])/len(df.gen))\n",
    "\n",
    "dis_pred = pd.DataFrame(vectors).T.loc[genders.index,:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab5ea8-ab4f-4950-b826-692b5503e267",
   "metadata": {},
   "source": [
    "Before creating the phonologicla predictors, we need to normalize the transcriptions, because a few sounds are coded on two characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82b7309-197a-4eb0-97f9-2d9f90aae219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    s=s.replace('œ̃','1')\n",
    "    s=s.replace('ɛ̃','5')\n",
    "    s=s.replace('ɑ̃','3')\n",
    "    return s.replace('ɔ̃','4')\n",
    "\n",
    "df['phon']=df.sg.apply(normalize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277f8ce-6d98-4d86-9bda-74dc6cc4c8e9",
   "metadata": {},
   "source": [
    "Now creating a DataFrame `phon_pred`. This is the concatenation of one-hot encodings of the last three characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68eb42f5-f0dc-4ab8-ac20-8aea78317969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1:#</th>\n",
       "      <th>-1:1</th>\n",
       "      <th>-1:3</th>\n",
       "      <th>-1:4</th>\n",
       "      <th>-1:5</th>\n",
       "      <th>-1:E</th>\n",
       "      <th>-1:a</th>\n",
       "      <th>-1:b</th>\n",
       "      <th>-1:d</th>\n",
       "      <th>-1:e</th>\n",
       "      <th>...</th>\n",
       "      <th>-3:ŋ</th>\n",
       "      <th>-3:œ</th>\n",
       "      <th>-3:ɔ</th>\n",
       "      <th>-3:ə</th>\n",
       "      <th>-3:ɛ</th>\n",
       "      <th>-3:ɥ</th>\n",
       "      <th>-3:ɲ</th>\n",
       "      <th>-3:ʁ</th>\n",
       "      <th>-3:ʃ</th>\n",
       "      <th>-3:ʒ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lexeme</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accident</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empiétement</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glabelle</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lancer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regardeur</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latence</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capitanat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aînée</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tragédie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>béchamel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24204 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             -1:#  -1:1  -1:3  -1:4  -1:5  -1:E  -1:a  -1:b  -1:d  -1:e  ...  \\\n",
       "lexeme                                                                   ...   \n",
       "accident        0     0     1     0     0     0     0     0     0     0  ...   \n",
       "empiétement     0     0     1     0     0     0     0     0     0     0  ...   \n",
       "glabelle        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "lancer          0     0     0     0     0     0     0     0     0     1  ...   \n",
       "regardeur       0     0     0     0     0     0     0     0     0     0  ...   \n",
       "...           ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "latence         0     0     0     0     0     0     0     0     0     0  ...   \n",
       "capitanat       0     0     0     0     0     0     1     0     0     0  ...   \n",
       "aînée           0     0     0     0     0     0     0     0     0     1  ...   \n",
       "tragédie        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "béchamel        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "             -3:ŋ  -3:œ  -3:ɔ  -3:ə  -3:ɛ  -3:ɥ  -3:ɲ  -3:ʁ  -3:ʃ  -3:ʒ  \n",
       "lexeme                                                                   \n",
       "accident        0     0     0     0     0     0     0     0     0     0  \n",
       "empiétement     0     0     0     1     0     0     0     0     0     0  \n",
       "glabelle        0     0     0     0     0     0     0     0     0     0  \n",
       "lancer          0     0     0     0     0     0     0     0     0     0  \n",
       "regardeur       0     0     0     0     0     0     0     0     0     0  \n",
       "...           ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "latence         0     0     0     0     0     0     0     0     0     0  \n",
       "capitanat       0     0     0     0     0     0     0     0     0     0  \n",
       "aînée           0     0     0     0     0     0     0     0     0     0  \n",
       "tragédie        0     0     0     0     0     0     0     0     0     0  \n",
       "béchamel        0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[24204 rows x 114 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = pd.get_dummies(df.phon.str[-1].loc[genders.index]).astype(int)\n",
    "one.columns=['-1:'+i for i in one.columns]\n",
    "two = pd.get_dummies(df.phon.str[-2].loc[genders.index]).astype(int)\n",
    "two.columns=['-2:'+i for i in two.columns]\n",
    "three = pd.get_dummies(df.phon.str[-3].loc[genders.index]).astype(int)\n",
    "three.columns=['-3:'+i for i in three.columns]\n",
    "phon_pred=pd.concat([one,two,three],axis=1)\n",
    "phon_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb5d92-20d1-4144-8078-3fb53d88749b",
   "metadata": {},
   "source": [
    "Now we can start training models. Hyperparameters have been optimized by grid search, I'm skipping the code for that.\n",
    "\n",
    "Note that using such a high number of estimators (500) leads to very long computation times. I really tried to see how far I could push this. I had reasonably good numbers with just 60 estimators, I recommend using that for exploratory purposes. \n",
    "\n",
    "Phonological prediction (takes 370s on my machine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cd3b450-5964-4f24-b3d5-b1e38b6e9d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848 (366s)\n"
     ]
    }
   ],
   "source": [
    "n=500\n",
    "lr=.1\n",
    "max_depth=15\n",
    "min_samples_split=10\n",
    "start = time.time()\n",
    "BT = GradientBoostingClassifier(n_estimators=n, \n",
    "                          learning_rate=lr, \n",
    "                          max_depth=max_depth, \n",
    "                          min_samples_split = min_samples_split,\n",
    "                          random_state=0,\n",
    "                          loss='log_loss')\n",
    "phon_pred_res = cross_val_predict(BT, phon_pred, genders, cv=10)\n",
    "acc = round(sum(phon_pred_res==genders)/len(genders),3)\n",
    "duration = int(round(time.time() -start,0))\n",
    "print(acc, ' (',duration,'s)',sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf0ec8-1d28-41d5-91c8-8677296c5308",
   "metadata": {},
   "source": [
    "Prediction from embeddings **beware, this takes about 7000s on my machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9b9bd5-0185-4779-a9ef-5bcfb4882cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735 (6832s)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "BT = GradientBoostingClassifier(n_estimators=n, \n",
    "                          learning_rate=lr, \n",
    "                          max_depth=max_depth, \n",
    "                          min_samples_split = min_samples_split,\n",
    "                          random_state=0,\n",
    "                          loss='log_loss')\n",
    "dis_pred_res = cross_val_predict(BT, dis_pred, genders, cv=10)\n",
    "acc = round(sum(dis_pred_res==genders)/len(genders),3)\n",
    "duration = int(round(time.time() -start,0))\n",
    "print(acc, ' (',duration,'s)',sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8777e8-0a12-4b8b-a987-c550f41d64da",
   "metadata": {},
   "source": [
    "Prediction from both phonology and embeddings **beware, this takes about 18000s on my machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a53053ac-5b93-4907-9d7f-11e6464cc8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888 (18111s)\n"
     ]
    }
   ],
   "source": [
    "both = pd.concat([dis_pred,phon_pred],axis=1)\n",
    "both.columns=both.columns.astype(str)\n",
    "\n",
    "start = time.time()\n",
    "BT = GradientBoostingClassifier(n_estimators=n, \n",
    "                          learning_rate=lr, \n",
    "                          max_depth=max_depth, \n",
    "                          min_samples_split = min_samples_split,\n",
    "                          random_state=0,\n",
    "                          loss='log_loss')\n",
    "both_res = cross_val_predict(BT, both, genders, cv=10)\n",
    "acc = round(sum(both_res==genders)/len(genders),3)\n",
    "duration = int(round(time.time() -start,0))\n",
    "print(acc, ' (',duration,'s)',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc63a77-91a4-4bf4-8b44-a4a5c943bb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
